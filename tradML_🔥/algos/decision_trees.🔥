"""
Decision Trees:

A supervised learning method used for both classification and regression tasks.
It creates a model that predicts the target variable by learning simple decision rules from the input features.
The tree structure consists of nodes (decision points), branches (possible outcomes), and leaves (final predictions).
It is interpretable and can handle both numerical and categorical data.

params:

max_depth: Int32  # Maximum depth of the tree
min_samples_split: Int32  # Minimum number of samples required to split an internal node
criterion: String  # Function to measure the quality of a split (e.g., "gini" or "entropy" for classification)

returns:

tree: Object  # The trained decision tree model
feature_importances: Tensor[DType.float32]  # Importance of each feature in making decisions
"""
from tensor import Tensor
from math import sqrt, log, exp
from random import rand, randint
from typing import List

from traditionalML_ðŸ”¥.tradML_ðŸ”¥.base_structs import Model, DataPoint

struct LinearRegression(Model):
    var weights: Tensor[DType.float32]
    var bias: Float32

    fn __init__(inout self, num_features: Int):
        self.weights = Tensor[DType.float32](num_features)
        self.bias = 0.0

    fn predict(self, input: Tensor[DType.float32]) -> Float32:
        return (self.weights * input).sum() + self.bias

    fn loss(self, prediction: Float32, actual: Float32) -> Float32:
        return (prediction - actual) ** 2

    fn train(self, data: List[DataPoint], learning_rate: Float32, epochs: Int):
        for _ in range(epochs):
            for point in data:
                prediction = self.predict(point.features)
                error = prediction - point.label
                self.weights -= learning_rate * error * point.features
                self.bias -= learning_rate * error

    export LinearRegression
